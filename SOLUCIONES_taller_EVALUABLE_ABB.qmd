---
title: "SOLUCIONES taller en grupo Mat3 GIN 2024-2025"
author: "Maria Kupriyenko, Jaume Juan Huguet, Kalyarat Asawapoom"
lang: es
format:
  html:
    theme: superhero
    toc: true
    toc_depth: 4
    html-math-method: katex
    code-tools: true
    code-fold: true
    collapse: true
    keep-md: true
    code-overflow: wrap
---

```{r setup, include=FALSE}

# Configuración inicial para el documento
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE,cache=FALSE)

# Carga de las librerías necesarias para el análisis de datos
library(tidyverse)
```

# Instrucciones para el taller

Se entrega en grupos que deben de estar constituidos en la actividad de grupos. Los grupos son de 2 o 3 ESTUDIANTES, loa caso especiales consultadlos con el profesor para que los autorice.

**Enlaces y Bibliografía**

-   [R for data science, Hadley Wickham, Garret Grolemund.](https://r4ds.had.co.nz/)
-   [Fundamentos de ciencia de datos con R.](https://cdr-book.github.io/)
-   [Tablas avanzadas: kable, KableExtra.](https://haozhu233.github.io/kableExtra/awesome_table_in_html.html)
-   [Geocomputation with R, Robin Lovelace, Jakub Nowosad, Jannes Muenchow](https://r.geocompx.org/)
-   Apuntes de R-basico y tidyverse moodel MAT3.

## Objetivo MALLORCA

Leeremos los siguientes datos de la zona de etiqueta `mallorca` con el código siguiente:

```{r}
# Carga de datos del objeto 'listings_common0_select'.
load("clean_data/mallorca/listing_common0_select.RData")
ls()  # Lista los objetos cargados en el entorno
str(listings_common0_select) # Muestra la estructura del objeto
```

**listings**

Hemos cargado el objeto `listings_common0_select` que contiene los datos de los 4 periodos de apartamentos de inside Airbnb de Mallorca con unas 15 ó 16 variables.

Notemos que cada apartamento:

-   queda identificado por id y por date que nos da el periodo en la que apareció el dato.
-   así que cada apartamento aparece 4 veces ya que hemos elegido solo los apartamentos que aparecen en las 4 muestras.
-   Las muestras son `r unique(listings_common0_select$date)`,

```{r}
unique(listings_common0_select$date)
```

**reviews**

Estos datos necesitan leerse de forma adecuada, las columnas 1, 2 y 4 deben ser de tipo `character` las otras son correctas

```{r}
# Carga de datos de reseñas desde un archivo CSV comprimido
reviews=read_csv("data/mallorca/2023-12-17/reviews.csv.gz")
str(reviews)
head(reviews)
```

**neighbourhoods.csv**

Son dos columnas y la primera es una agrupación de municipios (están NA) y la segunda es el nombre del municipio

```{r}
# Carga de datos de municipios desde un archivo CSV.
municipios=read_csv("data/mallorca/2023-12-17/neighbourhoods.csv")
str(municipios)
head(municipios)
```

**neighbourhoods.geojson**

Es el mapa de Mallorca, o podemos leer así:

```{r}
library(sf)
library(tmap)

# Leer el archivo GeoJSON
geojson_sf <- sf::st_read("data/mallorca/2024-09-13/neighbourhoods.geojson")

# Crear un mapa

# interactivo
tmap_mode("plot") # Cambiar a modo  view/plot   que es interactivo/estático
tm_shape(geojson_sf) +
  tm_polygons(col = "cyan", alpha = 0.6) +
  tm_layout(title = "Mapa - GeoJSON Mallorca con municipios")
```

Tenéis que consultar en la documentación de inside Airbnb para saber que significa cada variable. Os puede ser útil leer los ficheros [DATA_ABB_modelo_de_datos.html](DATA_ABB_modelo_de_datos.html) y [DATA_ABB_modelo_de_datos.pdf](DATA_ABB_modelo_de_datos.html) en los que se explica el modelo de datos de inside Airbnb y como se cargan en el espacio de trabajo.

Responder las siguientes preguntas con formato Rmarkdown (.Rmd) o quarto (.qmd) y entregad la fuente un fichero en formato html como salida del informe. Se puntúa la claridad de la respuesta, la calidad de la redacción y la corrección de la respuesta.

## Pregunta 1 (**1punto**)

Del fichero con los datos de listings `listing_common0_select.RData` calcula los estadísticos descriptivos de las variable `price` y de la variable `number_of_reviews` agrupados por municipio y por periodo.

Presenta los resultados con una tabla de kableExtra.

### Solución

```{r}
# Analizamos los precios
aux_price = listings_common0_select %>% select(id,
                                              date, 
                                              price, 
                                              neighbourhood_cleansed)
# Agrupamos los datos por municipio y fecha y calculamos los estadísticos descriptivos                                         
table_price = aux_price %>% group_by(neighbourhood_cleansed, date) %>%
   summarise(mean_price = mean(price, na.rm = TRUE) ,   # Promedio
            sd_price = sd(price, na.rm = TRUE) ,        # Desviación estándar
            median_price = median(price, na.rm = TRUE), # Mediana
            min_price = min(price, na.rm = TRUE),       # Mínimo
            max_price = max(price, na.rm = TRUE),       # Máximo
            n_price = n()) %>% arrange(neighbourhood_cleansed, date)  # Conteo y ordenar por municipio y fecha

# Presentación de resultados en tabla HTML
knitr::kable(table_price,"html") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)

# Analizamos reviews        
aux_reviews = listings_common0_select %>% select(id,
                                              date, 
                                              number_of_reviews, 
                                              neighbourhood_cleansed)
                                              
table_reviews = aux_reviews %>% group_by(neighbourhood_cleansed, date) %>%
   summarise(mean_reviews = mean(number_of_reviews, na.rm = TRUE) ,     # Promedio
            sd_reviews = sd(number_of_reviews, na.rm = TRUE) ,          # Desvación estándar
            median_reviews = median(number_of_reviews, na.rm = TRUE),   # Mediana
            min_reviews = min(number_of_reviews, na.rm = TRUE),         # Mínimo
            max_reviews = max(number_of_reviews, na.rm = TRUE),         # Máximo
            n_reviews = n()) %>% arrange(neighbourhood_cleansed, date)  # Conteo y ordenar por municipio y fecha
      
# Presentación de resultados en tabla HTML
knitr::kable(table_reviews,"html") %>%
  kableExtra::kable_styling(bootstrap_options = "striped", full_width=F)
```

## Pregunta 2 (**1punto**)

Consideremos las variables `price` y `number_of_reviews` de Pollença y Palma del periodo "2024-09-13", del fichero `listing_common0_select.RData`. Estudiad si estos datos se aproximan a una distribución normal gráficamente. Para ello, dibujad el histograma, la función "kernel-density" que aproxima la densidad y la densidad de la normal de media y varianza las de las muestras de las variables `price` (para precios mayores de 50 y menores de 400) y `number_of_reviews` para Palma y Pollença

### Solución

```{r}

# Analizamos los precios
price2 = listings_common0_select %>% filter(neighbourhood_cleansed %in% c("Pollença", "Palma de Mallorca") & date == "2024-09-13")

# Juntamos los precios de los dos municipios en un solo vector
str(price2)
price2=price2$price   # Extraemos solo la columna price
str(price2)

# Filtramos los precios para que estén entre 50 y 400
price2=na.omit(price2[price2>50 & price2<400])

# Calculamos la media y la desviación estándar de los precios filtrados.
mean_price=mean(price2)
sd_price=sd(price2)
mean_price 
sd_price


# Creamos data frame de precios con los datos filtrados
data <- data.frame(price2 = price2)

# Generamos el gráfico con ggplot2
ggplot(data, aes(x = price2)) + 
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "black") + 
  geom_density(color = "red", size = 1) + 
  stat_function (fun = dnorm, args = list(mean = mean_price, sd = sd_price), color = "blue", size = 1) +
  labs(
    title = "Histograma de precios Pollença y Palma\n 2024-09-13", # Título
    x = "Precios",               # Etiqueta del eje x
    y = "Densidad muestral") +   # Etiqueta del eje Y
  ylim(0, 0.006) +               # Ajustamos los límites del eje
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5)) # Centra el título
    
```
El histograma representa la distribución de los precios para valores filtrados entre 50 y 400.
La curva roja representa la estimación de densidad mediante un kernel density (no paramétrica). Esta sigue la distribución empírica de los datos. Mientras que la curva azul, que representa densidad de una distribución normal basada en la media y la desviación estándar de la muestra no ajuste perfectamente a los datos especialmente en la parte izquierda.

En conclusión, la distribución de precios no sigue exactamente una distribución normal.


Ahora calculamos las estadíticas con la variable number_of_reviews
```{r}
# Analizamos reviews

# Filtramos los datos seleccionando solo los registros de los municipios Pollença y Palma de Mallorca
# y del periodo "2024-09-13".
reviews2 = listings_common0_select %>%filter(neighbourhood_cleansed %in% c("Pollença", "Palma de Mallorca") & date == "2024-09-13")
str(reviews2)

reviews2 = reviews2$number_of_reviews.  # Extraemos solo number_of_reviews
str(reviews2)

reviews2 = na.omit(reviews2)            # Eliminamos valores faltantes (NA) del vector para evitar errores en los cálculos
str(reviews2)


# Calculamos la media y la desviación estándar
mean_reviews <- mean(reviews2)
sd_reviews <- sd(reviews2)
mean_reviews
sd_reviews

# Creamos data frame de reviews con los datos filtrados
data_reviews <- data.frame(reviews2 = reviews2)

# Generamos el gráfico con ggplot2
ggplot(data_reviews, aes(x = reviews2)) + 
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black") + 
  geom_density(color = "red", size = 1) + 
  stat_function(fun = dnorm, args = list(mean = mean_reviews, sd = sd_reviews), color = "blue", size = 1) +
  labs(
    title = "Histograma de número de reviews \n Pollença y Palma",
    x = "Número de reviews",    # Etiqueta del eje x
    y = "Densidad muestral"     # Etiqueta del eje y
  ) +
  ylim(0,0.006) +               # Ajustamos los límites del eje
  theme_minimal() + 
  theme(plot.title = element_text(hjust=0.5))

```
El histograma muestra la distribución empírica de los datos de number_of_reviews.
La curva roja corresponde a la estimación de la densidad Kernel, que sigue de cerca la forma del histograma, especialmente la concentración de datos en valores bajos.
La curva azul representa la distribución normal teórica calculada con la media y la desviación estándar de la muestra. Esta no se ajusta bien a los datos, ya que decrece más rápido en comparación con la densidad Kernel.
En conclusión, la variable number_of_reviews no sigue una distribución normal.


## Pregunta 3 (**1punto**)

Con los datos de `listings_common0_select` de todos los periodos, contrastar si la media del precio en Pollença es igual a la de Palma **contra** que es mayor que en Palma para los precios mayores que 50 euros y menores de 400. Construid la hipótesis nula y alternativa, calculad el $p$-valor y el intervalo de confianza asociado al contraste. Justifica técnicamente la conclusión del contraste.

### Solución

Sea $\mu_{\texttt{Pollença}}$ y $\mu_{Palma}$ las medias de los precios en Pollença y Palma respectivamente. La hipótesis nula y aleternativa son:

$$
\left\{
\begin{aligned}
H_0 & : \mu_{\mathrm{\texttt{Pollença}}} = \mu_{\mathrm{Palma}} \\
H_1 & : \mu_{\mathrm{\texttt{Pollença}}} \leq \mu_{\mathrm{Palma}}
\end{aligned}
\right.
$$ Primero calculamos los datos que nos piden

```{r}
# Extraemos y limpiamos los precios de Pollença
price_Pollença = listings_common0_select %>%
filter(neighbourhood_cleansed == "Pollença" & price > 50 &
price < 400) %>% select(price)
str(price_Pollença) # Verificamos la estructura del dataframe (tibble)
price_Pollença = na.omit(price_Pollença$price) # Eliminamos valores NA y convertimos en un vector numérico
str(price_Pollença)

# Extraemos y limpiamos los precios de Palma
price_Palma = listings_common0_select %>%
filter(neighbourhood_cleansed == "Palma de Mallorca" & price > 50 & price < 400) %>% select(price)
str(price_Palma) # Verificamos la estructura del dataframe (tibble)
price_Palma = na.omit(price_Palma$price) # Eliminamos valores NA y convertimos en un vector numérico
str(price_Palma)
```

Hemos guardado en los objetos `price_Pollença` y `price_Palma` los precios de Pollença y Palma respectivamente sin NA's y comprendidos entre 50 y 400 euros.

El contraste se puede realizar con la función `t.test` de R muestras independientes y tamaños `r length(price_Pollença)` y `r length(price_Palma)` respectivamente.

```{r}
# Contraste t para muestras independientes (hipótesis unilateral: Pollença <= Palma)
t.test(price_Pollença, price_Palma, alternative = "less", 
       mu = 0, conf.level = 0.95, var.equal = TRUE)
```

El p-valor es muy alto

```{r}
# Repetimos el contraste, pero sin asumir varianzas iguales
t.test(price_Pollença, price_Palma, alternative = "less", 
       mu = 0, conf.level = 0.95, var.equal = FALSE)
```

Para decidir si las varianzas son iguales o no hacemos

```{r}
# Verificamos si las varianzas son iguales entre ambas muestras
var.test(price_Pollença, price_Palma)
```

Y vemos que las varianzas no son iguales. Por tanto, el contraste se realiza con var.equal = FALSE.

## Pregunta 4 (**1punto**)

Con los datos de `listings_common0_select`, contrastar si las medias de los precios en Palma entre los periodos "2023-12-17" y "2024-03-23" son iguales contra que son menores en 2023. Construid la hipótesis nula y alternativa, calculad el $p$-valor y el intervalo de confianza asociado al contraste. Haced un diagrama de caja comparativo de los precios ~~por municipio~~ por periodo y coméntalo.

### Solución

Sea $\mu_{2023}$ Y $\mu_{2024} las medias de los precios en Palma en los periodos "2023-12-17" y "2024-03-23" respectivamente. La hipótesis nula y alternativa son:

```{r}
# Calculamos el contraste de hipótesis
# Las medias de los precios en Palma entre "2023-12-17" y "2024-03-23"
# H0: \( \mu_{2023} = \mu_{2024} \)
# H1: \( \mu_{2023} < \mu_{2024} \)

# Seleccionamos los precios de los periodos especificados
price_2023= listings_common0_select %>% filter(neighbourhood_cleansed=="Palma de Mallorca" & date=="2023-12-17") %>% arrange(id)

price_2024= listings_common0_select %>% filter(neighbourhood_cleansed=="Palma de Mallorca" & date=="2024-03-23") %>% arrange(id)

# Verificamos que sean los mismos apartamentos
all(table(price_2023$id==price_2024$id))

```
Luego son los mismo apartamentos así que tenemos muestras dependientes el precio del apartamento en 2023 y el del MISMO apartamento en 2024. El test es:

```{r}
# Realizamos el test t para muestras dependientes (paired)
t.test(price_2023$price, price_2024$price, alternative = "less", mu=0, conf.level=0.95,paired=TRUE)

```
Aceptamos que la media es mayor en 2024 que en 2023

Interpretación del resultado:

No se rechaza la hipótesis nula: no hay evidencia suficiente para afirmar que los precios en 2023 son menores que los de 2024.

El p-valor alto (0.9916) y el intervalo de confianza (-Inf, 33.83) sugieren que cualquier diferencia observada podría deberse al azar.

Aunque la media en 2024 parece mayor (diferencia promedio = 20.05), esta no es estadísticamente significativa.

```{r}
# Creamos el diagrama de caja comparativo por periodo
library(ggplot2)

price_comparison <- listings_common0_select %>% 
  filter(neighbourhood_cleansed == "Palma de Mallorca" & date %in% c("2023-12-17", "2024-03-23")) %>% 
  mutate(period = ifelse(date == "2023-12-17", "2023", "2024"))

ggplot(price_comparison, aes(x = period, y = price, fill = period)) +
  geom_boxplot() +
  labs(
    title = "Comparación de precios por periodo",
    x = "Periodo",
    y = "Precio",
    fill = "Periodo"
  ) +
  theme_minimal()

```
Observaciones del gráfico:

- Distribución central: Ambas cajas son similares en tamaño y ubicación. La mediana (línea dentro de las cajas) parece ligeramente más alta para 2024, sugiriendo un incremento moderado en los precios promedio.

- Rango de precios: Los precios muestran una alta dispersión, con valores atípicos muy elevados en ambos periodos. El rango de los valores extremos parece similar, aunque hay más puntos alejados del cuerpo principal de datos en 2024.

- Similitud general: Aunque se observa una ligera diferencia en las medianas y la posición de las cajas, estas no parecen lo suficientemente marcadas como para indicar un cambio significativo.

En conclusión, el gráfico apoya los resultados del test t: no hay evidencia de una diferencia estadísticamente significativa entre los precios de los dos periodos. Si bien 2024 muestra precios ligeramente más altos en promedio, la variación en los datos y la presencia de valores atípicos sugieren que la diferencia podría deberse al azar.

## Pregunta 5 (**1punto**)

Calcular la proporción de apartamentos de la muestra "2024-03-23" con media de valoración `review_scores_rating` mayor que 4 en Palma y en Pollença son iguales contra que son distintas. Construid un intervalo de confianza para la diferencia de proporciones.

### Solución

Sea $p_{\texttt{Pollença}}$ y $p_{\texttt{Palma}}$ las proporciones de apartamentos con media de valoración `review_scores_rating` mayor que 4 en Pollença y Palma respectivamente.

Calculemos las proporciones muestrales

```{r}
# Filtramos los datos de valoraciones para Pollença
rating_Pollença = listings_common0_select %>%
  filter(neighbourhood_cleansed == "Pollença" & date == "2024-03-23")
rating_Pollença = na.omit(rating_Pollença$review_scores_rating) # Eliminamos valores NA

# Filtramos los datos de valoraciones para Palma
rating_Palma = listings_common0_select %>%
  filter(neighbourhood_cleansed == "Palma de Mallorca" & date == "2024-03-23")
rating_Palma = na.omit(rating_Palma$review_scores_rating) # Eliminamos valores NA
```

Las proporciones y tamaño de las muestras son

```{r}
# Calculamos la proporción de apartamentos con valoración > 4 en Pollença
p_Pollença = mean(rating_Pollença > 4) # Proporción de valoraciones mayores a 4
n_Pollença = length(rating_Pollença)   # Número total de apartamentos evaluados

p_Pollença
```

```{r}
n_Pollença
```

```{r}
# Calculamos la proporción de apartamentos con valoración > 4 en Palma
p_Palma = mean(rating_Palma > 4) # Proporción de valoraciones mayores a 4
n_Palma = length(rating_Palma)   # Número total de apartamentos evaluados

p_Palma
```

```{r}
n_Palma
```

La hipótesis nula y alternativa son:

$$
\left\{
\begin{aligned}
H_0 & : p_{\text{Pollença}} = p_{\text{Palma}} \\
H_1 & : p_{\text{Pollença}} \neq p_{\text{Palma}}
\end{aligned}
\right.
$$ Para que obtengamos el contraste clásico de la Z y su intervalo de confianza ponemos el parámetro `correct=FALSE` para que no aplique la corrección de Yates.

```{r}
# Realizamos el contraste de proporciones
prop.test(c(sum(rating_Pollença > 4), sum(rating_Palma > 4)), # Sumas de éxitos
          c(n_Pollença, n_Palma),                             # Tamaños de las muestras
          alternative = "two.sided",                          # Hipótesis bilateral
          conf.level = 0.95,                                  # Nivel de confianza
          correct = FALSE)                                    # Sin corrección de Yates
```

Rechazamos la igualdad el intervalo de confianza es el que se ve pero lo podemos calcular también

```{r}

# Parámetro Z para un nivel de confianza del 95%
z <- qnorm(0.975)

# Error de margen
error_margen <- z * sqrt(
  p_Pollença * (1 - p_Pollença) / n_Pollença + 
  p_Palma * (1 - p_Palma) / n_Palma
)

# Intervalo de confianza
intervalo_confianza <- c(
  (p_Pollença - p_Palma) - error_margen,
  (p_Pollença - p_Palma) + error_margen
)

intervalo_confianza
```

## Pregunta 6 (**1punto**)

Calcular la proporción de apartamentos de los periodos "2023-12-17" y "2024-03-23" con media de valoración `review_scores_rating` mayor que 4 en Palma ~~y en Pollença~~ son iguales contra que son distintas.

### Solución

Ahora son proporciones de dos muestras dependientes. Las proporciones y tamaño de las muestras para los mismos id en cada periodo: "2023-12-17" y "2024-03-23" son:

Aunque ya estaba calculada recalculamos la de Palma 2024

```{r}
# Filtramos los datos de valoraciones para Palma de Mallorca en la fecha 2023-12-17
rating_2023 = listings_common0_select %>%
  filter(neighbourhood_cleansed == "Palma de Mallorca" & date == "2023-12-17") %>%
  arrange(id) %>% select(id, review_scores_rating)

# Filtramos los datos de valoraciones para Palma de Mallorca en la fecha 2024-03-23
rating_2024 = listings_common0_select %>%
  filter(neighbourhood_cleansed == "Palma de Mallorca" & date == "2024-03-23") %>%
  arrange(id) %>% select(id, review_scores_rating)

# Combinamos las valoraciones de ambas fechas utilizando un 'left join' por la columna 'id'
rating_23_24 = rating_2023 %>% left_join(rating_2024, by = "id")

# Creamos una tabla de frecuencias cruzadas para comparar las valoraciones > 4 en ambas fechas
tabla = table(rating_23_24$review_scores_rating.x > 4, rating_23_24$review_scores_rating.y > 4)

tabla
```

```{r}
# Realizamos la prueba de McNemar sobre la tabla de contingencia previamente calculada
mcnemar.test(tabla)
```

Luego lasa proporciones de las valoraciones superior a 4 son iguales en la muestra de 2023 y la de 2024

```{r}
# Eliminamos los valores NA (valores faltantes) de la columna review_scores_rating del conjunto de datos rating_2024
rating_2024 = na.omit(rating_2024$review_scores_rating)
```

## Pregunta 7 (**1punto**)

La [Zipf's law es una ley empírica](https://en.wikipedia.org/wiki/Zipf%27s_law#Word_frequencies_in_natural_languages) que dice que la frecuencia de las palabras en un texto es inversamente proporcional a su rango. Decidid si la ley se ajusta a los datos de la longitud de los comentarios de los apartamentos de la muestra "2023-12-17" de Palma. Para ello, haced un análisis de regresión lineal de la frecuencia de las longitudes de los comentarios de los apartamentos de Palma y el rango de las longitudes de los comentarios. Justificad la respuesta, estadísticamente y gráficamente.

Como ayuda estudiar el siguiente código, utilizadlo y comentadlo.

```{r}
# Cargar la librería necesaria
library(stringr)
head(reviews)

# Obtener las longitudes de los comentarios
length_rewiews=stringr::str_count(reviews$comments,"\\w+")
head(table(length_rewiews))
```

```{r}
# Frecuencia de las longitudes
aux=table(length_rewiews)
head(aux)
head(names(aux))

# Crear el tibble con frecuencias, rangos y logaritmos
tbl=tibble( L=as.numeric(names(aux)),Freq=as.numeric(aux),
            Rank=rank(L),Log_Freq=log(Freq),Log_Rank=log(Rank))
str(tbl)
```

```{r}
# Filtrar datos para rango entre 10 y 1000
tbl2=tbl %>% filter(Rank>10) %>% filter(Rank<1000)

# Regresión lineal simple de Freq contra Rank
sol1=lm(tbl2$Freq~tbl2$Rank)
summary(sol1)

# Regresión lineal de Freq contra Log_Rank
sol2=lm(tbl2$Freq~tbl2$Log_Rank)
summary(sol2)

# Regresión lineal de Log_Freq contra Log_Rank (relación log-log)
sol3=lm(tbl2$Log_Freq~tbl2$Log_Rank)
summary(sol3)
```

### Solución

Vamos a mostrar gráficamente los resultados obtenidos con el codigo anterior

```{r}
# Freq vs Rank
plot(tbl2$Rank, tbl2$Freq, col = "green", main = "Frecuencia vs Rango",
     xlab = "Rango", ylab = "Frecuencia", pch = 16, cex.lab = 1.5, cex.main = 1.8)
```
Esta gráfica muestra cómo varía la frecuencia de las longitudes de los comentarios en función de su rango.

Proporciona una visión general de la relación entre estas dos variables en escala lineal.

En general, la relación no parece seguir una línea recta clara en escala lineal, lo que indica que el modelo lineal simple no es apropiado para analizar esta relación.
```{r}
# Rank vs Log_Freq
plot(tbl2$Rank, tbl2$Log_Freq, col = "blue", main = "Rango vs Log(Frecuencia)",
     xlab = "Rango", ylab = "Log(Frecuencia)", pch = 16, cex.lab = 1.5, cex.main = 1.8)

```
Representa el rango en el eje x y el logaritmo de la frecuencia en el eje y.

Introduce el logaritmo para reducir la disparidad en las frecuencias altas, facilitando la observación de patrones más sutiles.

Si bien hay una tendencia decreciente, la relación sigue sin ser completamente lineal, lo que sugiere que una escala log-log podría ser más adecuada.
```{r}
# Freq vs Log_Rank
plot(tbl2$Log_Rank, tbl2$Freq, col = "red", main = "Frecuencia vs Log(Rango)",
     xlab = "Log(Rango)", ylab = "Frecuencia", pch = 16, cex.lab = 1.5, cex.main = 1.8)
```
Representa la frecuencia en el eje y y el logaritmo del rango en el eje x.

Permite observar si la frecuencia depende logarítmicamente del rango.

No se observa una relación lineal clara, lo que refuerza la necesidad de escalar ambas variables logarítmicamente.
```{r}
# Log_Freq vs Log_Rank
plot(tbl2$Log_Rank, tbl2$Log_Freq, col = "purple", main = "Log(Frecuencia) vs Log(Rango)",
     xlab = "Log(Rango)", ylab = "Log(Frecuencia)", pch = 16, cex.lab = 1.5, cex.main = 1.8)

```
Representa el logaritmo de la frecuencia en el eje y y el logaritmo del rango en el eje x.

Evalúa la Ley de Zipf, ya que una relación lineal en esta escala indica una ley potencial, con pendiente cercana a -1.

En esta escala log-log, los puntos generalmente se alinean, lo que sugiere que la Ley de Zipf puede ajustarse a los datos.